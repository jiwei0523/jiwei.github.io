
<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Wei Ji's Homepage</title>
<meta name="description" content="Wei Ji, Research Fellow in National University of Singapore. Computer Vision, Video Understanding, Vision and Language).">
<meta name="keywords" content="Wei Ji, National University of Singapore, multi media, video understanding, deep learning, machine learning">

<link rel="stylesheet" type="text/css" href="./files/weiji.css">
<!-- <script type="text/javascript" async="" src="./files/ga.js"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39532305-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script> -->

<style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>


<body>

<div id="content">

<div id="news">
    <h2>News</h2><br>
    <font size="3px">
	    
	    
    <b> February 2023</b><br>
    <span class="easylink">
     Two full papers are accepted by CVPR, about video moment retrieval and spatial-temporal video grounding.
    </span><br><br>
    </font>
	
	
    <b> November 2022</b><br>
    <span class="easylink">
     Two full papers are accepted by AAAI, about video-audio domain generalization and video-based fake news detection.
    </span><br><br>
    </font>
	
    <b> October 2022</b><br>
    <span class="easylink">
     One full paper is accepted by WSDM, about microvideo-Product retrieval.
    </span><br><br>
    </font>
	
    <b> October 2022</b><br>
    <span class="easylink">
     Two full papers are accepted by EMNLP, about video question answering and pretrained vision-language model.
    </span><br><br>
    </font>	
	    
    <b> July 2022</b><br>
    <span class="easylink">
     One full paper is accepted by ECCV, about scene graph generation.
    </span><br><br>
    </font>
	
	
    <b> May 2022</b><br>
    <span class="easylink">
     One full paper is accepted by TIP, about image super-resolution.
    </span><br><br>
    </font>	 
	
    <b> April 2022</b><br>
    <span class="easylink">
     One full paper is accepted by SIGIR'22, about conversational search.
    </span><br><br>
    </font>	    
	    
    <b> March 2022</b><br>
    <span class="easylink">
     One full paper is accepted by CVPR'22, about video question answering.
    </span><br><br>
    </font>
	
    <b> Dec 2021</b><br>
    <span class="easylink">
     Three full papers are accepted by AAAI'22, about video question answering, grounded situation recognition, and image quality assessment.
    </span><br><br>
    </font>
	    
	    
    <b> August 2021</b><br>
    <span class="easylink">
     One full paper is accepted by ACM MM'21, about video relation detection.
    </span><br><br>
    </font>
	    
    <b> July 2021</b><br>
    <span class="easylink">
     One full paper is accepted by SIGIR'21, about natural language video localization.
    </span><br><br>
    </font>
	
    <b> May 2021</b><br>
    <span class="easylink">
      We are hosting the 3rd Video Relation Understanding Grand Challenge (ACM MM2021, Chengdu). Please visit <a href="https://videorelation.nextcenter.org" target="_blank">here</a> for details.
    </span><br><br>
    </font>
	
    <b> December 2020</b><br>
    <span class="easylink">
      One full paper is accepted by AAAI'21, about natural language video localization.
    </span><br><br>
    </font>

    <b> August 2020</b><br>
    <span class="easylink">
      I have successfully defended my thesis and got the PhD degree! My thesis title is "Research on pixel-level semantic understanding based on deep learning".
    </span><br><br>
    </font>

</div>

<div id="left">
<table style="background-color:white;">
<tbody><tr nosave="">
<td valign="CENTER">
<img src="./images/weiji.JPG" height="250" align="left">
</td>

<td valign="CENTER" width="2%">
</td>

<td valign="CENTER" halign="LEFT">
<font size="+0">
<b><font size="+2">Wei Ji&nbsp;</font></b>
<!--<p style="margin-left:0px;">
<img src="./images/name.png", height="60">
</p>-->
<p style="margin-left:0px;">
<b>Research Fellow</b>
</p><p style="margin-left:0px;">
<a href="http://www.nextcenter.org/", target="_blank">NExT++</a><br/>
<a href="https://www.comp.nus.edu.sg/", target="_blank">School of Computing</a><br/>
<a href="http://www.nus.edu.sg", target="_blank">National University of Singapore</a><br/>
</p><p style="margin-left:0px;">
Computing 1, Computing Drive, Singapore 117417<br>
</p><p style="margin-left:0px;">
Email: weiji0523 AT gmail.com</a><br>
</p><p style="margin-left:0px;">
Email: jiwei AT nus.edu.sg</a><br>
&bull; <a href="https://scholar.google.com/citations?user=69OFB-AAAAAJ&hl=en">Google Scholar</a> <br>
</p></font><p><font size="+0">
</font>
</p></td>
</tr>
</tbody></table>

<div style="margin-top:20px;">
    I am a research fellow in <a href="http://www.nextcenter.org/">NExT++</a>, School of Computing, National University of Singapore. I have published several papers in top conferences such as SIGIR, CVPR, ECCV, ACM MM, EMNLP 
    and journals including TPAMI, TIP and TCYB. My research interests include Cross-modal Retrieval, Vision and Language, Video Understanding, et, al.
    Moreover, I have served as the PC member for top-tier conferences/journals, including SIGIR, CVPR, ICCV, ECCV, AAAI, ACM MM, EMNLP, IJCV, TIP, TMM, etc.
    
</div>

<h2 style="CLEAR: both">Experiences</h2>
<table>
  <tbody><tr>
    <td> <span class="title">Postdoc Research Fellow</span>, National University of Singapore, November 2020 - Present   <br>
			Advisior: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a> (<a href="http://www.nextcenter.org/">NExT++: NUS-Tsinghua-Southampton Extreme Search Center</a>)
		</td></tr></tbody>
</table>





<!-- =======================================================================!-->

<div id="papers">
<h2 style="CLEAR: both">Publications <a href="https://scholar.google.com/citations?user=69OFB-AAAAAJ&hl=en" target="_blank">Google Scholar</a></h2>
</br>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://jiwei0523.github.io/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">WINNER: Weakly-supervised hIerarchical decompositioN and aligNment for spatio-tEmporal video gRounding.</span> 
      <br>Mengze Li, Han Wang, Wenqiao Zhang, Jiaxu Miao,<b>Wei Ji</b>, Zhou Zhao, Shengyu Zhang, Fei Wu.
    <br>CVPR 2023 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://jiwei0523.github.io/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Are Binary Annotations Sufficient? Video Moment Retrieval via Hierarchical Uncertainty-based Active Learning.</span> 
      <br><b>Wei Ji</b>, Renjie Liang, Zhedong Zheng, Wenqiao Zhang, Shengyu Zhang, Juncheng, Li and Mengze Li, Tat-Seng Chua.
    <br>CVPR 2023 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://jiwei0523.github.io/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Video-Audio Domain Generalization via Confounder Disentanglement.</span> 
      <br>Shengyu Zhang, Xusheng Feng, Wenyan Fan, Wenjing Fang, Fuli Feng, <b>Wei Ji</b>, Li Shuo, Li Wang, Shanshan Zhao, Zhou Zhao, Tat-Seng Chua, Fei Wu.
    <br>AAAI 2023 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2211.10973.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News Detection on Short Video Platforms</span> 
      <br>Peng Qi, Yuyan Bu, Juan Cao, <b>Wei Ji</b>, Ruihao Shui, Junbin Xiao, Danding Wang, Tat-Seng Chua
    <br>AAAI 2023 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://jiwei0523.github.io/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Multi-queue Momentum Contrast for Microvideo-Product Retrieval</span> 
      <br>Yali Du, Yinwei Wei, <b>Wei Ji</b>, Fan Liu, Xin Luo, Liqiang Nie
    <br>WSDM 2023 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2205.11169" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models</span> 
      <br>Yuan Yao, Qianyu Chen, Ao Zhang, <b>Wei Ji</b>, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun
    <br>EMNLP 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2203.01225" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Video Question Answering: Datasets, Algorithms and Challenges</span> 
      <br>Yaoyao Zhong, Junbin Xiao, <b>Wei Ji</b>, Yicong Li, Weihong Deng, Tat-Seng Chua
    <br>EMNLP 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="doi.acm.org?doi=3477495.3532063" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Structured and Natural Responses Co-generation for Conversational Search</span> 
      <br>Chenchen Ye, Lizi Liao, Fuli Feng, <b>Wei Ji</b>, Tat-Seng Chua
    <br>SIGIR 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2203.11654.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Fine-Grained Scene Graph Generation with Data Transfer</span> 
      <br>Ao Zhang, Yuan Yao, Qianyu Chen, <b>Wei Ji</b>, Zhiyuan Liu, Maosong Sun, Tat-Seng Chua
    <br>ECCV 2022 (oral)&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2104.03926.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Conditional Meta-Network for Blind Super-Resolution with Multiple Degradations</span> 
      <br>Guanghao Yin, Wei Wang, Zehuan Yuan, <b>Wei Ji</b>, Dongdong Yu, Shouqian Sun, Tat-Seng Chua, Changhu Wang
    <br>TIP 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Invariant grounding for video question answering</span> 
      <br>Yicong Li, Xiang Wang, Junbin Xiao, <b>Wei Ji</b>, Tat-Seng Chua
    <br>CVPR 2022 (oral, Best Paper Finalist) &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2202.13123" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Content-Variant Reference Image Quality Assessment via Knowledge Distillation</span> 
      <br>Guanghao Yin, Wei Wang, Zehuan Yuan, Chuchu Han, <b>Wei Ji</b>, Shouqian Sun, Changhu Wang
    <br>AAAI 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2112.05375" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Rethinking the Two-Stage Framework for Grounded Situation Recognition</span> 
      <br>Meng Wei, Long Chen, <b>Wei Ji</b>, Xiaoyu Yue, Tat-Seng Chua
    <br>AAAI 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2112.06197" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Video as Conditional Graph Hierarchy for Multi-Granular Question Answering</span> 
      <br>Junbin Xiao, Angela Yao, Zhiyuan Liu, Yicong Li, <b>Wei Ji</b>, Tat-Seng Chua
    <br>AAAI 2022 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2105.12694?ref=https://githubhelp.com" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Deep Learning for Weakly-Supervised Object Detection and Localization: A Survey</span> 
      <br>Feifei Shao, Long Chen, Jian Shao, <b>Wei Ji</b>, Shaoning Xiao, Lu Ye, Yueting Zhuang, Jun Xiao
    <br>Neurocomputing &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3479232" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">VidVRD 2021: The Third Grand Challenge on Video Relation Detection</span> 
      <br><b>Wei Ji</b>, Yicong Li, Meng Wei, Xindi Shang, Junbin Xiao, Tongwei Ren, Tat-Seng Chua
    <br>ACM MM 2021 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462823" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Deconfounded Video Moment Retrieval with Causal Intervention</span> 
      <br>Xun Yang, Fuli Feng, <b>Wei Ji</b>, Meng Wang, Tat-Seng Chua
    <br>SIGIR 2021 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475263" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Video Visual Relation Detection via Iterative Inference</span> 
      <br>Xindi Shang, Yicong Li, Junbin Xiao, <b>Wei Ji</b>, Tat-Seng Chua
    <br>ACM MM 2021 &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://www.aaai.org/AAAI21Papers/AAAI-6267.XiaoS.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Boundary Proposal Network for Two-Stage Natural Language Video Localization</span> 
      <br>Shaoning Xiao, Long Chen, Songyang Zhang, <b>Wei Ji</b>, Jian Shao, Lu Ye, Jun Xiao
    <br>AAAI 2021&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://ieeexplore.ieee.org/abstract/document/9126215" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Context-Aware Graph Label Propagation Network for Saliency Detection</span>
        <br><b>Wei Ji</b>, Xi Li, Lina Wei, Fei Wu, Yueting Zhuang
    <br>IEEE Transactions on Image Processing (TIP 2020) &nbsp;&nbsp;
  </td>
  </tr>
 </tbody>
</table>



<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://ieeexplore.ieee.org/abstract/document/8943115" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Human-centric clothing segmentation via deformable semantic locality-preserving network</span>
        <br><b>Wei Ji</b>, Xi Li, Fei Wu, Zhijie Pan, Yueting Zhuang
    <br>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2019) &nbsp;
  </td>
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://ieeexplore.ieee.org/abstract/document/8563043" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Context-aware deep spatiotemporal network for hand pose estimation from depth images</span>
        <br>Yiming Wu, <b>Wei Ji</b>, Xi Li, Gang Wang, Jianwei Yin, Fei Wu
    <br>IEEE Transactions on Cybernetics (TCYB 2018) &nbsp;
  </td>
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://ieeexplore.ieee.org/abstract/document/8322285" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Multi-task structure-aware context modeling for robust keypoint-based object tracking</span>
        <br>Xi Li, Liming Zhao, <b>Wei Ji</b>, Yiming Wu, Fei Wu, Ming-Hsuan Yang, Dacheng Tao, Ian Reid
    <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI 2018) &nbsp;
  </td>
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://www.researchgate.net/profile/Jiabao-Cui/publication/326205821_Semantic_Locality-Aware_Deformable_Network_for_Clothing_Segmentation/links/5cab5c3e299bf118c4bad81a/Semantic-Locality-Aware-Deformable-Network-for-Clothing-Segmentation.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Semantic Locality-Aware Deformable Network for Clothing Segmentation</span>
        <br><b>Wei Ji</b>, Xi Li, Yueting Zhuang, Omar El Farouk Bourahla, Yixin Ji, Shihao Li, Jiabao Cui
    <br>International Joint Conference on Artificial Intelligence (IJCAI 2018) &nbsp;
  </td>
  </tr>
 </tbody>
</table>





<h2 style="CLEAR: both;">Professional Services</h2>
<table><tbody><tr><td>
<!-- 	Local Chair of <span class="title">CCIS 2019</span> (IEEE International Conference on Cloud Computing and Intelligence Systems) <br> -->
    Program Committee Member of <span class="title">ACL (2023) </span> <br>  
    Program Committee Member of <span class="title">SIGIR (2023) </span> <br> 
    Program Committee Member of <span class="title">CVPR (2022,2023) </span> <br>
    Program Committee Member of <span class="title">ICCV (2023) </span> <br>
    Program Committee Member of <span class="title">ECCV (2022) </span> <br>
    Program Committee Member of <span class="title">AAAI (2021,2022,2023) </span> <br>
    Program Committee Member of <span class="title">ACMMM (2021,2022) </span> <br>
    Program Committee Member of <span class="title">EMNLP (2022) </span> <br>
    Program Committee Member of <span class="title">ACM Multimedia Asia (2021) </span> <br>
    Invited Reviewer for <span class="title">International Journal of Computer Vision (IJCV)</span> <br>
    Invited Reviewer for <span class="title">IEEE Transactions on Image Processing (TIP)</span> <br>
    Invited Reviewer for <span class="title">IEEE Transactions on Multimedia (TMM)</span> <br>
    Invited Reviewer for <span class="title">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</span> <br>
</td></tr></tbody></table>



<h2 style="CLEAR: both;">Honors</h2>

<table><tbody><tr><td>
  <span class="title">Outstanding Graduate, Zhejiang University&nbsp;&nbsp; 2020</span> &nbsp;&nbsp;
</td></tr></tbody></table>

<table><tbody><tr><td>
  <span class="title">Distinguished Doctoral Scholarship, Zhejiang University&nbsp;&nbsp; 2018-2019</span> &nbsp;&nbsp;
</td></tr></tbody></table>



<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=6IxMkD9AxgkXmtT-CMTMolftstwgqiD1ExJBl3I8mPE&cl=ffffff&w=a"></script>

</div>
</div>



</body></html>
